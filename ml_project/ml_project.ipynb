{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Importing Libraries"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"outputs":[],"source":["# basic python imports\n","from collections import defaultdict\n","import os\n","\n","# Basic Data Science Imports\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","#from PIL import Image\n","\n","# Visualization\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","sns.set_style('whitegrid')\n","%matplotlib inline\n","\n","# Splitting data\n","from sklearn.model_selection import train_test_split\n","\n","# Metrics imports\n","from sklearn.metrics import confusion_matrix, classification_report\n","from sklearn.preprocessing import LabelEncoder\n","\n","# Deep Learning imports\n","import tensorflow as tf\n","print('TensoFlow Version: ', tf.__version__)\n","\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.applications.resnet import ResNet50\n","from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, CSVLogger\n","from tensorflow.keras.layers import Dense, Flatten, GlobalAveragePooling2D, BatchNormalization, Dropout\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.utils import to_categorical\n","\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Reading Data of Class Labels"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Define absolute path to your data\n","absolute_path = '/Users/diegogaray/Documents/Github/cpe429_project/ml_project/data/shorter_input/'\n","\n","# Read label information\n","lab = pd.read_csv(os.path.join(absolute_path, 'frameAnnotations.csv'))\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Visualizing countplot of the classes"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Initialize a defaultdict to hold the counts. A defaultdict is used so that\n","# keys that are not currently in the dictionary default to a value of 0.\n","counts = defaultdict(int)\n","\n","path = '/Users/diegogaray/Documents/Github/cpe429_project/ml_project/data/shorter_input/'\n","\n","# Iterate over the files in the directory\n","for filename in os.listdir(path):\n","    # Check if the file is an image (ends with .png)\n","    if filename.endswith('.png'):\n","        # The class label is the part of the filename before the first underscore\n","        class_label = filename.split('_')[0]\n","        # Increment the count for this class label\n","        counts[class_label] += 1\n","\n","# Convert the counts to a regular dictionary and print it\n","d = dict(counts)\n","print(d)\n","\n","total = 0\n","for value in d.values():\n","    total += value\n","\n","print(f\"There have been a total of {total} images identified\")\n","    \n","\n","# Create the plot\n","plt.figure(figsize=(20, 50))\n","sns.barplot(y=list(d.keys()), x=list(d.values()), palette='Set3')\n","plt.ylabel('Label')\n","plt.xlabel('Count of Samples/Observations')\n","plt.show()\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Reading Image Data"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Initialize list to hold the data\n","data = []\n","\n","# Iterate over the files in the directory\n","for filename in os.listdir(path):\n","    # Check if the file is an image (ends with .png)\n","    if filename.endswith('.png'):\n","        # The class label is the part of the filename before the first underscore\n","        class_label = filename.split('_')[0]\n","        # Append the filename and class label to the data\n","        data.append([filename, class_label])\n","\n","# Convert the data to a DataFrame\n","df = pd.DataFrame(data, columns=['filename', 'class'])\n","\n","# nb_classes = df['class'].nunique()\n","\n","datagen = ImageDataGenerator(rescale=1./255., validation_split=0.25)\n","\n","train_generator = datagen.flow_from_dataframe(\n","    dataframe=df,\n","    directory=path,\n","    x_col=\"filename\",\n","    y_col=\"class\",\n","    subset=\"training\",\n","    batch_size=32,\n","    seed=42,\n","    shuffle=True,\n","    class_mode=\"categorical\",\n","    target_size=(32,32))\n","\n","valid_generator = datagen.flow_from_dataframe(\n","    dataframe=df,\n","    directory=path,\n","    x_col=\"filename\",\n","    y_col=\"class\",\n","    subset=\"validation\",\n","    batch_size=32,\n","    seed=42,\n","    shuffle=True,\n","    class_mode=\"categorical\",\n","    target_size=(32,32))\n","\n","X, y = train_generator.next()\n","print(f\"Data Shape   :{X.shape}\\nLabels shape :{y.shape}\")"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Sample Images of Dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Get one batch of images and their corresponding labels\n","X_batch, y_batch = next(train_generator)\n","fig, axes = plt.subplots(10, 10, figsize=(18, 18))\n","\n","for i, ax in enumerate(axes.flat):\n","    # Draw a random image from the batch\n","    r = np.random.randint(X_batch.shape[0])\n","    image = X_batch[r]\n","    \n","    ax.imshow(image, interpolation='nearest')\n","    ax.grid(False)\n","    ax.axis('off')\n","    ax.set_title('Label: '+str(np.argmax(y_batch[r])))\n","\n","plt.show()\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Dividing data into **train** and **test** in the split percentage of 80:20"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# encoding class values as integers\n","encoder = LabelEncoder()\n","encoder.fit(df['class'])\n","encoded_Y = encoder.transform(df['class'])\n","# convert integers to one hot encoded\n","Y = to_categorical(encoded_Y)\n","\n","# Split the training data\n","X_train, X_test, y_train, y_test = train_test_split(df['filename'], Y, test_size=0.20, random_state=11)\n","\n","print(\"Train Shape: {}\\nTest Shape : {}\".format(X_train.shape, X_test.shape))"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Customising ResNet50 model  "]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Decide whether or not we want to use an old model we've already trained or completely create a new one\n","continue_training = True # Set this to False if you want to train a new model"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# \n","if continue_training and os.path.exists(\"bestest_model.keras\"):\n","    print(\"Loading saved model\")\n","    model = tf.keras.models.load_model(\"bestest_model.keras\")\n","else:\n","    print(\"Initializing a new model\")\n","    # Customising ResNet50 model  \n","    img_rows = 32\n","    img_cols = 32\n","    img_channels = 3\n","    resnet = ResNet50(weights= None, include_top=False, input_shape= (img_rows,img_cols,img_channels))\n","    nb_classes = len(train_generator.class_indices)\n","    x = resnet.output\n","    x = GlobalAveragePooling2D()(x)\n","    x = Dropout(0.5)(x)\n","    predictions = Dense(nb_classes, activation= 'softmax')(x)\n","    model = Model(inputs = resnet.input, outputs = predictions)\n","\n","\n","\n","x = resnet.output\n","x = GlobalAveragePooling2D()(x)\n","x = Dropout(0.5)(x)\n","predictions = Dense(nb_classes, activation= 'softmax')(x)\n","model = Model(inputs = resnet.input, outputs = predictions)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Give out a summary of the Model"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["model.summary()"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Visualising Model Architecture"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["plot_model(model, show_layer_names=True, show_shapes =True, to_file='model.png', dpi=350)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Compiling the Model"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Creating Callbacks"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["model_check = ModelCheckpoint('model_checkpoint.h5', monitor='val_accuracy', verbose=0, save_best_only=True, mode='max')\n","\n","# what stops the code from ending early\n","early = EarlyStopping(monitor='val_accuracy', min_delta=0, patience=7, verbose=0, mode='max', restore_best_weights=True)\n","\n","reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=7, min_lr=0.001)\n","\n","csv_logger = CSVLogger('train_log.csv', separator=',')\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Fitting Model with Data"]},{"cell_type":"code","execution_count":46,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["89/89 [==============================] - ETA: 0s - loss: 2.4943 - accuracy: 0.4619"]}],"source":["n_epochs = 25\n","#history = model.fit_generator(train_generator, epochs=n_epochs, validation_data=valid_generator, callbacks = [model_check, early, reduce_lr, csv_logger])\n","# Use model.fit instead of model.fit_generator\n","history = model.fit(train_generator, epochs=n_epochs, validation_data=valid_generator, callbacks = [model_check, early, reduce_lr, csv_logger])\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Saving the model\n","model.save(\"bestest_model.keras\")"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Evaluate the Model"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["loss, acc = model.evaluate(valid_generator, steps=len(valid_generator))\n","print('Accuracy: ', acc, '\\nLoss    : ', loss)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["q = len(list(history.history['loss']))\n","plt.figure(figsize=(12, 6))\n","sns.lineplot(x = range(1, 1+q), y = history.history['accuracy'], label = 'Accuracy')\n","sns.lineplot(x = range(1, 1+q), y = history.history['loss'], label = 'Loss')\n","plt.xlabel('#epochs')\n","plt.ylabel('Training')\n","plt.legend();"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["plt.figure(figsize=(12, 6))\n","sns.lineplot(x = range(1, 1+q), y = history.history['accuracy'], label = 'Train')\n","sns.lineplot(x = range(1, 1+q), y = history.history['val_accuracy'], label = 'Validation')\n","plt.xlabel('#epochs')\n","plt.ylabel('Accuracy')\n","plt.legend();"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["plt.figure(figsize=(12, 6))\n","sns.lineplot(x = range(1, 1+q), y = history.history['loss'], label = 'Train')\n","sns.lineplot(x = range(1, 1+q), y = history.history['val_loss'], label = 'Validation')\n","plt.xlabel('#epochs')\n","plt.ylabel('Loss')\n","plt.legend();"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Predict class labels of the test data"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["%%time"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# pred = np.argmax(model.predict(X_test), axis = 1)\n","# Define a function to load and preprocess an image\n","def load_and_preprocess_image(filename):\n","    img = tf.keras.preprocessing.image.load_img(os.path.join(path, filename), target_size=(32, 32)) \n","    img = tf.keras.preprocessing.image.img_to_array(img)\n","    img = img / 255.0  # Rescale pixel values\n","    img = np.expand_dims(img, axis=0)  # Add batch dimension\n","    return img\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Load and preprocess the images in X_test\n","X_test_images = np.concatenate([load_and_preprocess_image(filename) for filename in X_test])\n","\n","# Now predict the labels\n","pred = np.argmax(model.predict(X_test_images), axis=1)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Classification Report"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["class_labels = train_generator.class_indices\n","labels = [k for k, v in sorted(class_labels.items(), key=lambda item: item[1])]\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Confusion Matrix"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["cmat = confusion_matrix(np.argmax(y_test, axis=1), pred)\n","plt.figure(figsize=(16,16))\n","sns.heatmap(cmat, annot = True, cbar = False, cmap='Paired', fmt=\"d\", xticklabels=labels, yticklabels=labels);"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Classwise Accuracy"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["classwise_acc = cmat.diagonal() / cmat.sum(axis=1) * 100\n","class_labels = train_generator.class_indices\n","class_labels = {v: k for k, v in class_labels.items()}\n","\n","# create a dictionary with class labels as keys and accuracies as values\n","accuracy_dict = {class_labels[i]: acc for i, acc in enumerate(classwise_acc)}\n","\n","# Now create a DataFrame, using a default accuracy for classes not in `accuracy_dict`\n","cls_acc = pd.DataFrame(\n","    {\n","        'Class_Label': sorted(class_labels.values()),  # Sort the class labels\n","        'Accuracy': [accuracy_dict.get(label, np.nan) for label in sorted(class_labels.values())]\n","    },\n","    columns=['Class_Label', 'Accuracy']\n",")\n","\n","# Hide the index\n","cls_acc_styled = cls_acc.style.set_table_styles([{'selector': 'th.row_heading', 'props': [('display', 'none')]}])\n","\n","# Apply formatting and create the bar chart\n","cls_acc_styled.format({\"Accuracy\": \"{:,.2f}\"}).bar(subset=[\"Accuracy\"], color='tomato')\n","\n","# Display the styled DataFrame\n","cls_acc_styled\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["type(X_test)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Finally, Lets see the predictions of **unseen data**"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Finally, Lets see the predictions of **unseen data**\n","fig, axes = plt.subplots(6, 6, figsize=(15, 15))\n","for i, ax in enumerate(axes.flat):\n","    r = np.random.randint(X_test.shape[0])\n","    filename = X_test.iloc[r]\n","    image = load_and_preprocess_image(filename)  # Load and preprocess the image\n","    label_true = np.argmax(y_test[r])\n","    label_pred = np.argmax(model.predict(image))\n","    \n","    # Convert the image back to the original scale (from [0, 1] to [0, 255])\n","    image = (image[0] * 255).astype('uint8')  # Index into the batch dimension to get the actual image\n","    \n","    ax.imshow(image)\n","    ax.grid(False)\n","    ax.axis('off')\n","    ax.set_title('Original: {} Predicted: {}'.format(label_true, label_pred))\n","\n","plt.show()\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["--- "]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.9"}},"nbformat":4,"nbformat_minor":4}
